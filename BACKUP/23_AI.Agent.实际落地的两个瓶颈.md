# [AI Agent 实际落地的两个瓶颈](https://github.com/humyna/gitblog/issues/23)

瓶颈是来自于 LLM 作为推理引擎不够强大。

- 现有的LLM虽然在某些领域的任务上表现不错，但对于需要多步复杂推理的任务，表现还是很弱。这主要是因为LLM的训练目标是next token prediction，而不是进行复杂的推理。所以在需要链状推理的任务上，LLM的表现仍有很大提升空间。这个提升空间来自于模型架构和数据上的优化。可以用更复杂的训练任务使LLM学习复杂推理，如问答、阅读理解、分步规划等。

- 同时，LLM 响应输入和执行任务的速度还很慢。目前尚在技术早期，大家对 LLM 的延迟宽容度还比较高。但未来对于许多应用来说，低延迟是至关重要的，其速度直接影响了知识工作者的工作效率。例如最极端的，在自动驾驶汽车或高频交易系统中，延迟的减小可能会直接影响到系统的性能和安全性。 因此需要通过知识蒸馏、模型压缩等方法缩小模型大小，降低计算量，并且等待大模型推理硬件和算法侧的持续优化。

**其中，延迟优化是工程问题，需要业界的时间来渐进式优化；更难的瓶颈还在复杂推理能力上，这是个需要被解决的科学问题，将随着科研的进展和 agent 行为序列数据的累积逐渐明朗。**